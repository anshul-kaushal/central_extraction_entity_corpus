{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfb48399-2471-4bcd-8a49-8847e58fcd22",
   "metadata": {},
   "source": [
    "# Interannotator agreement study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78735e20-47a6-46ab-9dbf-4738dc1cd3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.metrics.agreement import AnnotationTask\n",
    "from nltk.probability import ConditionalFreqDist, FreqDist\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a426d495-e616-4c5a-b6c6-e977daa8149a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success!\n"
     ]
    }
   ],
   "source": [
    "entity_dict = defaultdict(lambda: defaultdict(list))\n",
    "type_dict = defaultdict(lambda: defaultdict(list))\n",
    "annotation_path = 'annotation/'\n",
    "files = ['anshul_chao_annotated_anshul.csv',\n",
    " 'anshul_chao_annotated_chao.csv',\n",
    " 'anshul_wei_annotated_anshul.csv',\n",
    " 'anshul_wei_annotated_wei.csv',\n",
    " 'chao_wei_annotated_chao.csv',\n",
    " 'chao_wei_annotated_wei.csv']\n",
    "for i in files:\n",
    "    file_name = '_'.join(i.split('_')[:2])\n",
    "    read_file = pd.read_csv(annotation_path+i)\n",
    "    for title, entity, types in zip(read_file['Title'].tolist(), read_file['central_entity'].tolist(), read_file['type'].tolist()):\n",
    "        entity_dict[file_name][title.strip()].append(entity.strip())\n",
    "        type_dict[file_name][title.strip()].append(types.upper())\n",
    "\n",
    "# Assertions to check if we have the exact number of annotations\n",
    "assert len(type_dict['anshul_wei']) == 165\n",
    "assert len(type_dict['anshul_chao']) == 170\n",
    "assert len(type_dict['chao_wei']) == 165\n",
    "assert len(entity_dict['anshul_wei']) == 165\n",
    "assert len(entity_dict['anshul_chao']) == 170\n",
    "assert len(entity_dict['chao_wei']) == 165\n",
    "print('success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdb2c97c-3305-4328-bad3-45d7c8949c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success!\n"
     ]
    }
   ],
   "source": [
    "entity_triples = []\n",
    "type_triples = []\n",
    "for name, dicts in type_dict.items():\n",
    "    for title, annotation in dicts.items():\n",
    "        type_triples.append(('c1', title, annotation[0]))\n",
    "        type_triples.append(('c2', title, annotation[1]))\n",
    "for name, dicts in entity_dict.items():\n",
    "    for title, annotation in dicts.items():\n",
    "        entity_triples.append(('c1', title, annotation[0]))\n",
    "        entity_triples.append(('c2', title, annotation[1]))\n",
    "# Assertions to check if we have the exact number of annotations\n",
    "assert len(entity_triples) == 1000\n",
    "assert len(type_triples) == 1000\n",
    "print('success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e1494a-c8b8-4d7b-aa87-40e75885e9e5",
   "metadata": {},
   "source": [
    "The interannotator agreement measures:      \n",
    "For the **central entity** annotation, we have decided to use the percentage agreement, which calculates observed agreement across all coders and items, as the label class in the central entity annotation does not have a particular distribution.     \n",
    "For the central entity **type** annotation, we have decided to use the Scott's Ï€ since the label 'FILM' occurs the most compared to other labels, which was observed by all annotators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bced177-79d5-44ac-8fe6-72196410f397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The interannotator agreement for entity annotation is: 0.94\n",
      "The interannotator agreement for type annotation is: 0.87\n"
     ]
    }
   ],
   "source": [
    "annotation_entity = AnnotationTask(entity_triples)\n",
    "annotation_type = AnnotationTask(type_triples)\n",
    "print('The interannotator agreement for entity annotation is:', round(annotation_entity.avg_Ao(), 2))\n",
    "print('The interannotator agreement for type annotation is:', round(annotation_type.pi(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa86b5e-00d7-4a1a-a238-07dfe8d1e43e",
   "metadata": {},
   "source": [
    "The interannotator agreements are 0.94 and 0.87 for the central entity and type annotations respectively. The results show that the annotation is very reliable.         \n",
    "The annotators have all followed the [annotation plan](https://github.ubc.ca/mds-cl-2021-22/523_group_9/blob/master/milestone_2/annotation_plan.ipynb) to ensure the annotation quality. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
