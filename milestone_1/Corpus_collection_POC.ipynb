{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8de72181-fa30-4016-9527-df134e06d9c7",
   "metadata": {},
   "source": [
    "# Corpus collection POC (proof-of-concept)\n",
    "\n",
    "This section contains the corpus collection process.     \n",
    "Currently, we are looking at extracting the news articles that are published between 2022-01-01 and 2022-02-15, within topics of Politics, Film, Technology, Business and Science, using [The Guardian OpenPlatform](https://open-platform.theguardian.com).    \n",
    "\n",
    "\n",
    "## Instruction\n",
    "\n",
    "- Run the code chunks below to obtain corpus.tsv file that contains the article category and the article content. \n",
    "- If no file is created after running the code, it is very likely that the key has reached its limits, please register for a developer key [here](https://open-platform.theguardian.com/access/), and replace the **MY_API_KEY** variable with your key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f90e24-1c1b-4cc1-8b81-40bbed0ca4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day  0\n",
      "...page 1\n",
      "day  1\n",
      "...page 1\n",
      "day  2\n",
      "...page 1\n",
      "day  3\n",
      "...page 1\n",
      "...page 2\n",
      "day  4\n",
      "...page 1\n",
      "...page 2\n",
      "day  5\n",
      "...page 1\n",
      "...page 2\n",
      "day  6\n",
      "...page 1\n",
      "...page 2\n",
      "day  7\n",
      "...page 1\n",
      "day  8\n",
      "...page 1\n",
      "day  9\n",
      "...page 1\n",
      "...page 2\n",
      "day  10\n",
      "...page 1\n",
      "...page 2\n",
      "day  11\n",
      "...page 1\n",
      "...page 2\n",
      "day  12\n",
      "...page 1\n",
      "...page 2\n",
      "day  13\n",
      "...page 1\n",
      "...page 2\n",
      "day  14\n",
      "...page 1\n",
      "day  15\n",
      "...page 1\n",
      "day  16\n",
      "...page 1\n",
      "...page 2\n",
      "day  17\n",
      "...page 1\n",
      "...page 2\n",
      "day  18\n",
      "...page 1\n",
      "...page 2\n",
      "day  19\n",
      "...page 1\n",
      "...page 2\n",
      "day  20\n",
      "...page 1\n",
      "...page 2\n",
      "day  21\n",
      "...page 1\n",
      "day  22\n",
      "...page 1\n",
      "...page 2\n",
      "day  23\n",
      "...page 1\n",
      "...page 2\n",
      "day  24\n",
      "...page 1\n",
      "...page 2\n",
      "day  25\n",
      "...page 1\n",
      "...page 2\n",
      "day  26\n",
      "...page 1\n",
      "...page 2\n",
      "day  27\n",
      "...page 1\n",
      "...page 2\n",
      "day  28\n",
      "...page 1\n",
      "day  29\n",
      "...page 1\n",
      "day  30\n",
      "...page 1\n",
      "...page 2\n",
      "day  31\n",
      "...page 1\n",
      "...page 2\n",
      "day  32\n",
      "...page 1\n",
      "...page 2\n",
      "day  33\n",
      "...page 1\n",
      "...page 2\n",
      "day  34\n",
      "...page 1\n",
      "...page 2\n",
      "day  35\n",
      "...page 1\n",
      "day  36\n",
      "...page 1\n",
      "day  37\n",
      "...page 1\n",
      "...page 2\n",
      "day  38\n",
      "...page 1\n",
      "...page 2\n",
      "day  39\n",
      "...page 1\n",
      "...page 2\n",
      "day  40\n",
      "...page 1\n",
      "...page 2\n",
      "day  41\n",
      "...page 1\n",
      "...page 2\n",
      "day  42\n",
      "...page 1\n",
      "day  43\n",
      "...page 1\n",
      "day  44\n",
      "...page 1\n",
      "...page 2\n",
      "day  45\n",
      "...page 1\n",
      "...page 2\n"
     ]
    }
   ],
   "source": [
    "# imports \n",
    "import json\n",
    "import requests\n",
    "from datetime import date, timedelta\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Guardian api\n",
    "# apply for your key here: https://open-platform.theguardian.com/access/\n",
    "MY_API_KEY = '1956fa1c-fa95-4b0b-a5a8-0436216ab868'\n",
    "\n",
    "# I followed this example:\n",
    "# code modified from https://gist.github.com/dannguyen/c9cb220093ee4c12b840\n",
    "\n",
    "API_ENDPOINT = 'http://content.guardianapis.com/search'\n",
    "my_params = {\n",
    "    'from-date': \"\",\n",
    "    'to-date': \"\",\n",
    "    'order-by': \"newest\",\n",
    "    'show-fields': 'all',\n",
    "    'page-size': 200,\n",
    "    'api-key': MY_API_KEY\n",
    "}\n",
    "\n",
    "topics = ['Politics', 'Film', 'Technology', 'Business', 'Science']\n",
    "\n",
    "\n",
    "start_date = date(2022, 1, 1)\n",
    "end_date = date(2022,2, 15)\n",
    "all_days = range((end_date - start_date).days + 1)\n",
    "all_results = []\n",
    "for day_count in all_days:\n",
    "    print('day ', day_count)\n",
    "    dt = start_date + timedelta(days=day_count)\n",
    "    datestr = dt.strftime('%Y-%m-%d')\n",
    "    my_params['from-date'] = datestr\n",
    "    my_params['to-date'] = datestr\n",
    "    page_count = 1\n",
    "    num_pages = 1\n",
    "    while page_count <= num_pages:\n",
    "        print(\"...page\", page_count)\n",
    "        my_params['page'] = page_count\n",
    "        resp = requests.get(API_ENDPOINT, my_params)\n",
    "        data = resp.json()\n",
    "        # [topic, text] list\n",
    "        all_results.extend([[i[\"sectionName\"], i['fields']['bodyText']] for i in data['response']['results']])\n",
    "        # if there is more than one page, also look at other pages too\n",
    "        page_count += 1\n",
    "        num_pages = data['response']['pages']\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68af44f9-dede-4dd4-ab16-c45fde687829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business</td>\n",
       "      <td>The Bank of England is facing fierce criticism...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business</td>\n",
       "      <td>Treasury officials have quietly introduced a n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business</td>\n",
       "      <td>The UK’s cost of living crisis escalated in De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business</td>\n",
       "      <td>The global surge in demand for energy could sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business</td>\n",
       "      <td>Bullying, sexual harassment and racism are com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>Technology</td>\n",
       "      <td>The sharing of some of the most insidious imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>Technology</td>\n",
       "      <td>The billionaire entrepreneur Elon Musk’s brain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>Technology</td>\n",
       "      <td>Fossil fuel companies and firms that work clos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>Technology</td>\n",
       "      <td>Uber’s food delivery service Uber Eats has tur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>Technology</td>\n",
       "      <td>$20bn (£14.7bn) has been wiped off the value o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1554 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Topic                                               Text\n",
       "0       Business  The Bank of England is facing fierce criticism...\n",
       "1       Business  Treasury officials have quietly introduced a n...\n",
       "2       Business  The UK’s cost of living crisis escalated in De...\n",
       "3       Business  The global surge in demand for energy could sp...\n",
       "4       Business  Bullying, sexual harassment and racism are com...\n",
       "...          ...                                                ...\n",
       "1549  Technology  The sharing of some of the most insidious imag...\n",
       "1550  Technology  The billionaire entrepreneur Elon Musk’s brain...\n",
       "1551  Technology  Fossil fuel companies and firms that work clos...\n",
       "1552  Technology  Uber’s food delivery service Uber Eats has tur...\n",
       "1553  Technology  $20bn (£14.7bn) has been wiped off the value o...\n",
       "\n",
       "[1554 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter the results, and only keep the ones that is in our topics\n",
    "final_results = []\n",
    "for topic, text in all_results:\n",
    "    if topic in topics:\n",
    "        final_results.append([topic, text])\n",
    "\n",
    "# conver to pd dataframe, to sort them by topics (optional)\n",
    "final_df = pd.DataFrame(final_results, columns = ['Topic', 'Text'])\n",
    "final_df = final_df.sort_values('Topic').reset_index(drop=True)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a10b5f7-e46a-4e14-9201-7980974c6492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Politics      509\n",
       "Business      500\n",
       "Film          326\n",
       "Technology    135\n",
       "Science        84\n",
       "Name: Topic, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print number of documents in each category\n",
    "final_df['Topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e221e811-2f3a-4f62-8f92-e4a398cb83d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save our data in tsv file\n",
    "final_df.to_csv('corpus.tsv', sep=\"\\t\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
